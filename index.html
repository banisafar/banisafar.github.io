<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sahar Banisafar</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <div class="header-container">
            <div class="profile-section">
                <img src="images/crop2.png" alt="Sahar Banisafar" class="profile-photo" />
                
                <div class="profile-info">
                    <h1>Sahar Banisafar</h1>
                    <p>Data Scientist & Technical Writer</p>
                    <div class="social-links">
                        <a href="https://github.com/banisafar"><img src="images/github_logo.png" class="iico" alt="GitHub" /></a>
                        <a href="https://linkedin.com/in/banisafar"><img src="images/linkedin_logo1.png" class="iico" alt="LinkedIn" /></a>
                    </div>
                </div>
            </div>
            
            <nav>
                <a href="#about">About</a>
                <a href="#cv">CV</a>
            </nav>
        </div>
    </header>

    <div class="intro">
        <h2>Learning Notes on Artificial Intelligence</h2>
        <p>Documenting my explorations in machine learning, computer vision, and the mathematics underlying modern AI. I write to clarify my understanding and share practical insights with the community.</p>
    </div>

    <main>
        <ul class="post-list">
            <li class="post-item">
                <a href="article.html" class="post-title">Understanding Transformers: A Mathematician's Perspective</a>
                <p class="post-excerpt">A deep dive into the architecture that revolutionized NLP. We break down attention mechanisms, positional encodings, and the mathematical foundations that make transformers work, with practical examples using PyTorch.</p>
                <div class="post-meta">
                    <span class="tag">Deep Learning</span>
                    <span>Coming Soon</span>
                    <span>15 min read</span>
                </div>
            </li>

            <li class="post-item">
                <a href="bert_ft.html" class="post-title">Fine-Tuning DistilBERT for Text Classification: A Complete Implementation</a>
                <p class="post-excerpt">A practical guide to fine-tuning pretrained language models, covering dataset preparation, handling class imbalance, custom data collators, and training loops in PyTorch with HuggingFace Transformers. Includes full code and explanations of the mechanics beyond high-level APIs.</p>
                <div class="post-meta">
                    <span class="tag">NLP</span>
                    <span>January 2026</span>
                    <span>15 min read</span>
                </div>
            </li>
        </ul>
    </main>

    <footer>
        <p>Â© 2025 Sahar Banisafar</p>
    </footer>
</body>
</html>